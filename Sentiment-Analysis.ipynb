{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Info\n",
        "\n",
        "Yelp Reviews Sentiment Analysis\n",
        "\n",
        "Euiyoung Lee "
      ],
      "metadata": {
        "id": "brZpV8U3dVMb"
      },
      "id": "brZpV8U3dVMb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Description\n",
        "In this project we will demonstrate a supervised  learning model for classification of sentiments with a sample of Yelp reviews data and vector labels over two types of sentiments."
      ],
      "metadata": {
        "id": "xtqmNb5nd9UB"
      },
      "id": "xtqmNb5nd9UB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Import libraries"
      ],
      "metadata": {
        "id": "BW_KWEpRgbS3"
      },
      "id": "BW_KWEpRgbS3"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbDceMx8Qcha",
        "outputId": "57178c12-2d6b-4573-b581-58069d65509b"
      },
      "id": "zbDceMx8Qcha",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 55 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 53.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=a576f4305687f414316a1ab800839f65fe3f0e947e58fdf80b519c005677ec86\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/88/9e/58ef1f74892fef590330ca0830b5b6d995ba29b44f977b3926\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7156025d",
      "metadata": {
        "id": "7156025d"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession ,Row\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,FloatType\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsnqX3VMTc9i",
        "outputId": "a6f4683b-deee-40f4-c045-e74ccaa6f733"
      },
      "id": "EsnqX3VMTc9i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f731ae8f",
      "metadata": {
        "id": "f731ae8f",
        "outputId": "a0c6fa28-a472-48ee-fae2-fc8f0a62ca84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder\\\n",
        "          .appName(\"SentimentAnalysis\")\\\n",
        "          .getOrCreate()\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"text\", StringType(), True),\n",
        "    StructField(\"target\", IntegerType(), True)])\n",
        "\n",
        "project_folder = '/content/drive/MyDrive/CS777_BigDataAnalytics/term_project/'\n",
        "\n",
        "dfTextTarget = spark.read.csv(project_folder + 'small_preprocessed_review', \\\n",
        "                              header=False, schema=schema)\n",
        "dfTextTarget = dfTextTarget.dropna()\n",
        "dfTextTarget.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9712457f",
      "metadata": {
        "id": "9712457f",
        "outputId": "5055cb39-a3e1-44bc-f38d-ce5df3d58e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|                text|target|\n",
            "+--------------------+------+\n",
            "|horrible experien...|     0|\n",
            "|i went to the fre...|     0|\n",
            "|my phone dies at ...|     0|\n",
            "|another terrific ...|     1|\n",
            "|called on monday ...|     1|\n",
            "+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfTextTarget.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2627abc9",
      "metadata": {
        "id": "2627abc9",
        "outputId": "ee794dda-d1de-410b-e7c4-fc6791ec83b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69998"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dfTextTarget.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Split"
      ],
      "metadata": {
        "id": "OuJ0m9l9jhsE"
      },
      "id": "OuJ0m9l9jhsE"
    },
    {
      "cell_type": "code",
      "source": [
        "(train_set, test_set) = dfTextTarget.randomSplit([0.8, 0.2], seed = 2000)\n",
        "test_set.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICnziSSwty-S",
        "outputId": "b454de00-b87b-41b4-8dc1-896b87db5c50"
      },
      "id": "ICnziSSwty-S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13940"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5PWEcq2wlhc",
        "outputId": "a476fe86-a1e6-4e6e-a076-aa433af27df7"
      },
      "id": "R5PWEcq2wlhc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56058"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4dd6f9",
      "metadata": {
        "id": "4f4dd6f9"
      },
      "source": [
        "## Hashing TF - IDF -Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb15e129",
      "metadata": {
        "id": "bb15e129"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78163263",
      "metadata": {
        "id": "78163263",
        "outputId": "fcf60c0a-eccc-429f-e68d-20b70387584e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 11.7 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def eval_model(model_name,model):\n",
        "  \n",
        "  tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "  hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
        "  idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "  label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
        "  pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx,model])\n",
        "  pipelineFit = pipeline.fit(train_set)\n",
        "\n",
        "  predictions_train = pipelineFit.transform(train_set)\n",
        "  predictions_test = pipelineFit.transform(test_set)\n",
        "\n",
        "  train_accuracy = predictions_train.filter(predictions_train.label == predictions_train.prediction).count() / float(train_set.count())\n",
        "  test_accuracy = predictions_test.filter(predictions_test.label == predictions_test.prediction).count() / float(test_set.count())\n",
        "\n",
        "  evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "  train_roc_auc = evaluator.evaluate(predictions_train)\n",
        "  test_roc_auc = evaluator.evaluate(predictions_test)\n",
        "  metricsList = [(model_name,train_accuracy,test_accuracy,train_roc_auc,test_roc_auc)]\n",
        "  return metricsList\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schemaMetrics = StructType([\\\n",
        "  StructField('model', StringType(), True),\\\n",
        "  StructField('train_accuracy', FloatType(), True),\\\n",
        "  StructField('test_accuracy', FloatType(), True),\\\n",
        "  StructField('train_ROC_AUC', FloatType(), True),\\\n",
        "  StructField('test_ROC_AUC', FloatType(), True)])\n",
        "metrics = spark.createDataFrame([], schemaMetrics)"
      ],
      "metadata": {
        "id": "xZwprf42pL1L"
      },
      "id": "xZwprf42pL1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "logreg_metricsList = eval_model('LogReg', lr)\n",
        "# spark.createDataFrame(logreg_metricsList).write.csv(project_folder+'metrics')\n",
        "logreg = spark.createDataFrame(logreg_metricsList, schemaMetrics)\n",
        "metrics = metrics.union(logreg)\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDXE4fXv4tLQ",
        "outputId": "a10a894a-3ed9-488f-c4ad-9a869ef17357"
      },
      "id": "bDXE4fXv4tLQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+-------------+-------------+------------+\n",
            "| model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+------+--------------+-------------+-------------+------------+\n",
            "|LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "+------+--------------+-------------+-------------+------------+\n",
            "\n",
            "CPU times: user 787 ms, sys: 99 ms, total: 886 ms\n",
            "Wall time: 1min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF + LInear SVC"
      ],
      "metadata": {
        "id": "knBdx_S00xyx"
      },
      "id": "knBdx_S00xyx"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
        "lsvc_metricsList = eval_model('LinearSVC', lsvc)\n",
        "lsvc_metricsDF = spark.createDataFrame(lsvc_metricsList, schemaMetrics)\n",
        "metrics = metrics.union(lsvc_metricsDF)\n",
        "metrics.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvMo0lFv0wW1",
        "outputId": "2452864d-3a5d-4b3a-cf55-5cf450467706"
      },
      "id": "qvMo0lFv0wW1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+-------------+-------------+------------+\n",
            "|    model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+---------+--------------+-------------+-------------+------------+\n",
            "|   LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "|LinearSVC|     0.9407043|   0.90164995|   0.97813654|  0.94934887|\n",
            "+---------+--------------+-------------+-------------+------------+\n",
            "\n",
            "CPU times: user 478 ms, sys: 65.8 ms, total: 544 ms\n",
            "Wall time: 59.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF + Decision Tree"
      ],
      "metadata": {
        "id": "aKNyHp0W3A9w"
      },
      "id": "aKNyHp0W3A9w"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt_metricsList = eval_model('DecisionTree', dt)\n",
        "dt_metricsDF = spark.createDataFrame(dt_metricsList, schemaMetrics)\n",
        "metrics = metrics.union(dt_metricsDF)\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4KtZ9DO5OUP",
        "outputId": "d45eee1d-af16-4705-ad0c-3968911e3e61"
      },
      "id": "X4KtZ9DO5OUP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+-------------+-------------+------------+\n",
            "|       model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+------------+--------------+-------------+-------------+------------+\n",
            "|      LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "|   LinearSVC|     0.9407043|   0.90164995|   0.97813654|  0.94934887|\n",
            "|DecisionTree|    0.76986337|   0.77245337|    0.6773023|   0.6837623|\n",
            "+------------+--------------+-------------+-------------+------------+\n",
            "\n",
            "CPU times: user 2.41 s, sys: 303 ms, total: 2.72 s\n",
            "Wall time: 5min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4504c54",
      "metadata": {
        "id": "a4504c54"
      },
      "source": [
        "## CountVectorizer + IDF + Logistic Regression\n",
        "There's another way that you can get term frequecy for IDF (Inverse Document Freqeuncy) calculation. It is CountVectorizer in SparkML. Apart from the reversibility of the features (vocabularies), there is an important difference in how each of them filters top features. In case of HashingTF it is dimensionality reduction with possible collisions. CountVectorizer discards infrequent tokens.\n",
        "\n",
        "Let's see if performance changes if we use Countvectorizer instead of HashingTF."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def count_vectorizer_model(model_name,model):\n",
        "  \n",
        "  tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "  cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
        "  # hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
        "  idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "  label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
        "  pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx,model])\n",
        "  pipelineFit = pipeline.fit(train_set)\n",
        "\n",
        "  predictions_train = pipelineFit.transform(train_set)\n",
        "  predictions_test = pipelineFit.transform(test_set)\n",
        "\n",
        "  train_accuracy = predictions_train.filter(predictions_train.label == predictions_train.prediction).count() / float(train_set.count())\n",
        "  test_accuracy = predictions_test.filter(predictions_test.label == predictions_test.prediction).count() / float(test_set.count())\n",
        "\n",
        "  evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "  train_roc_auc = evaluator.evaluate(predictions_train)\n",
        "  test_roc_auc = evaluator.evaluate(predictions_test)\n",
        "  metricsList = [(model_name,train_accuracy,test_accuracy,train_roc_auc,test_roc_auc)]\n",
        "  \n",
        "  return metricsList\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "041J27Gx6OcM",
        "outputId": "09958723-18b3-4e5b-acd7-a2d872487f7a"
      },
      "id": "041J27Gx6OcM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 11.9 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "metricsList = count_vectorizer_model('CVIDF_LogReg', lr)\n",
        "metricsDF = spark.createDataFrame(metricsList, schemaMetrics)\n",
        "metrics = metrics.union(metricsDF)\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr46MUsa7_5a",
        "outputId": "be926edc-f0d7-42fb-a2d7-2a413fbde23a"
      },
      "id": "vr46MUsa7_5a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+-------------+-------------+------------+\n",
            "|       model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+------------+--------------+-------------+-------------+------------+\n",
            "|      LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "|   LinearSVC|     0.9407043|   0.90164995|   0.97813654|  0.94934887|\n",
            "|DecisionTree|    0.76986337|   0.77245337|    0.6773023|   0.6837623|\n",
            "|CVIDF_LogReg|     0.9999643|    0.8231707|   0.99999946|  0.86521894|\n",
            "+------------+--------------+-------------+-------------+------------+\n",
            "\n",
            "CPU times: user 627 ms, sys: 97.1 ms, total: 724 ms\n",
            "Wall time: 1min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22e8a00",
      "metadata": {
        "id": "e22e8a00"
      },
      "source": [
        "## N-gram Implementation with Chi Squared Selector\n",
        "Spark does not automatically combine features from different n-grams, so I had to use VectorAssembler in the pipeline, to combine the features I get from each n-grams.\n",
        "\n",
        "I first tried to extract around 16,000 features from unigram, bigram, trigram. This means I will get around 48,000 features in total. Then I implemented Chi Squared feature selection to reduce the features back to 16,000 in total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1be70d",
      "metadata": {
        "id": "ab1be70d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import NGram, VectorAssembler\n",
        "from pyspark.ml.feature import ChiSqSelector\n",
        "\n",
        "def build_trigrams(inputCol=[\"text\",\"target\"], n=3):\n",
        "    tokenizer = [Tokenizer(inputCol=\"text\", outputCol=\"words\")]\n",
        "    ngrams = [\n",
        "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "\n",
        "    cv = [\n",
        "        CountVectorizer(vocabSize=2**14,inputCol=\"{0}_grams\".format(i),\n",
        "            outputCol=\"{0}_tf\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
        "\n",
        "    assembler = [VectorAssembler(\n",
        "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
        "        outputCol=\"rawFeatures\"\n",
        "    )]\n",
        "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
        "    selector = [ChiSqSelector(numTopFeatures=2**14,featuresCol='rawFeatures', outputCol=\"features\")]\n",
        "    lr = [LogisticRegression(maxIter=100)]\n",
        "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+selector+lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac35db9a",
      "metadata": {
        "id": "ac35db9a",
        "outputId": "1f1eb6fa-5fb0-4394-c21f-c633001a508e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.45 s, sys: 338 ms, total: 2.79 s\n",
            "Wall time: 6min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trigram_pipelineFit = build_trigrams().fit(train_set)\n",
        "# predictions = trigram_pipelineFit.transform(val_set)\n",
        "# accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "# roc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "# # print accuracy, roc_auc\n",
        "# print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
        "# print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictions_train = trigram_pipelineFit.transform(train_set)\n",
        "predictions_test = trigram_pipelineFit.transform(test_set)\n",
        "\n",
        "train_accuracy = predictions_train.filter(predictions_train.label == predictions_train.prediction).count() / float(train_set.count())\n",
        "test_accuracy = predictions_test.filter(predictions_test.label == predictions_test.prediction).count() / float(test_set.count())\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "train_roc_auc = evaluator.evaluate(predictions_train)\n",
        "test_roc_auc = evaluator.evaluate(predictions_test)\n",
        "metricsList = [('Ngrams_ChiSqSelector',train_accuracy,test_accuracy,train_roc_auc,test_roc_auc)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLPtk2FBTB75",
        "outputId": "5c73b3de-17b6-4e4f-f36f-9f42bd705195"
      },
      "id": "oLPtk2FBTB75",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 865 ms, sys: 208 ms, total: 1.07 s\n",
            "Wall time: 1min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metricsDF = spark.createDataFrame(metricsList, schemaMetrics)\n",
        "metrics = metrics.union(metricsDF)\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfc8iD3vTz_A",
        "outputId": "c0affbe4-eaa0-429d-95d3-0a308911a7be"
      },
      "id": "nfc8iD3vTz_A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "|               model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "|              LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "|           LinearSVC|     0.9407043|   0.90164995|   0.97813654|  0.94934887|\n",
            "|        DecisionTree|    0.76986337|   0.77245337|    0.6773023|   0.6837623|\n",
            "|        CVIDF_LogReg|     0.9999643|    0.8231707|   0.99999946|  0.86521894|\n",
            "|Ngrams_ChiSqSelector|     0.9999465|    0.8779771|   0.99999934|   0.9294032|\n",
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-gram Implementation without Chi Squared Selector"
      ],
      "metadata": {
        "id": "r4VLC_qjWby0"
      },
      "id": "r4VLC_qjWby0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071fe88b",
      "metadata": {
        "id": "071fe88b"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import NGram, VectorAssembler\n",
        "\n",
        "def build_ngrams_wocs(inputCol=[\"text\",\"target\"], n=3):\n",
        "    tokenizer = [Tokenizer(inputCol=\"text\", outputCol=\"words\")]\n",
        "    ngrams = [\n",
        "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "\n",
        "    cv = [\n",
        "        CountVectorizer(vocabSize=5460,inputCol=\"{0}_grams\".format(i),\n",
        "            outputCol=\"{0}_tf\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
        "\n",
        "    assembler = [VectorAssembler(\n",
        "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
        "        outputCol=\"features\"\n",
        "    )]\n",
        "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
        "    lr = [LogisticRegression(maxIter=100)]\n",
        "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0ed565",
      "metadata": {
        "id": "ac0ed565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310730e3-f47b-48fd-8163-e807814b59c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 s, sys: 276 ms, total: 2.28 s\n",
            "Wall time: 4min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "trigramwocs_pipelineFit = build_ngrams_wocs().fit(train_set)\n",
        "predictions_train = trigramwocs_pipelineFit.transform(train_set)\n",
        "predictions_test = trigramwocs_pipelineFit.transform(test_set)\n",
        "\n",
        "train_accuracy = predictions_train.filter(predictions_train.label == predictions_train.prediction).count() / float(train_set.count())\n",
        "test_accuracy = predictions_test.filter(predictions_test.label == predictions_test.prediction).count() / float(test_set.count())\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "train_roc_auc = evaluator.evaluate(predictions_train)\n",
        "test_roc_auc = evaluator.evaluate(predictions_test)\n",
        "metricsList = [('Ngrams_WithOut_ChiSq',train_accuracy,test_accuracy,train_roc_auc,test_roc_auc)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fcda2cd",
      "metadata": {
        "id": "2fcda2cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3872a0b1-0a4d-4d5f-c6ef-b9dee31fdaed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "|               model|train_accuracy|test_accuracy|train_ROC_AUC|test_ROC_AUC|\n",
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "|              LogReg|     0.9999643|    0.8167862|    0.9999995|   0.8584581|\n",
            "|           LinearSVC|     0.9407043|   0.90164995|   0.97813654|  0.94934887|\n",
            "|        DecisionTree|    0.76986337|   0.77245337|    0.6773023|   0.6837623|\n",
            "|        CVIDF_LogReg|     0.9999643|    0.8231707|   0.99999946|  0.86521894|\n",
            "|Ngrams_ChiSqSelector|     0.9999465|    0.8779771|   0.99999934|   0.9294032|\n",
            "|Ngrams_WithOut_ChiSq|     0.9999822|   0.87560976|   0.99999946|   0.9284153|\n",
            "+--------------------+--------------+-------------+-------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "metricsDF = spark.createDataFrame(metricsList, schemaMetrics)\n",
        "metrics = metrics.union(metricsDF)\n",
        "metrics.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.toPandas().to_csv(project_folder+'metrics.csv')"
      ],
      "metadata": {
        "id": "Jkg94H4sqlkL"
      },
      "id": "Jkg94H4sqlkL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The end."
      ],
      "metadata": {
        "id": "S5lvo15ton2y"
      },
      "id": "S5lvo15ton2y"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}